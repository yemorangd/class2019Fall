{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pru_Keras_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dWy-vuUGPPq",
        "colab_type": "text"
      },
      "source": [
        "Kaggle의  Prudential Life Assessment 문제를 간단한 Keras 신경망으로 풀어본 코드\n",
        "\n",
        "출처 : https://www.kaggle.com/c/prudential-life-insurance-assessment\n",
        "\n",
        "Keras 및 Tensorflow 1.x를 사용.\n",
        "\n",
        "Google Colab환경에서 GPU 기반으로 작동하도록 작성하였음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmJVrIWWG31q",
        "colab_type": "text"
      },
      "source": [
        "기본적으로 제공된 데이터에 대해 scikit-learn이 제공하는 regression 기반 asending imputation을 적용해 전처리를 진행하였음. \n",
        "\n",
        "일부 데이터칼럼의 경우 결측치 = 0, 비결측치 = 1로 처리.\n",
        "\n",
        "전체 데이터의 10% 가량을 Validation set으로 사용.\n",
        "\n",
        "최종 결과물 산출에는 100노드짜리 은닉층 3개로 구성된 신경망을 사용함,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkydHDy-R8S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/drive/\", force_remount = True)\n",
        "path = '/content/drive/My Drive/ML/Prudential'\n",
        "os.chdir(path)\n",
        "data_in_path = './input/'\n",
        "data_out_path = './out/'\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brXqcImYgYSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "impu_train = pd.read_csv(data_in_path + 'train_regression_01_Discrete_descending.csv')\n",
        "data_train = impu_train.loc[:,'Product_Info_1':'Response']\n",
        "\n",
        "#Value가 A2, B3 등 string인 Product_Info_2 (index 2) 를 받아서, 첫 알파벳에 따라서 정수값 매기고 뒤의 숫자를 더하기\n",
        "def string2int(string):\n",
        "  return ord(string[:1])+int(string[1:2])\n",
        "data_train[\"Product_Info_2\"] = data_train[\"Product_Info_2\"].apply(lambda s: string2int(s))\n",
        "\n",
        "#1-8 Response 값을 0-7로 변환하여 별개 변수에 할당\n",
        "Response = data_train.pop('Response')\n",
        "Response = Response-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0zNIsPhFQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#신경망 구성\n",
        "import tensorflow\n",
        "model = tensorflow.keras.models.Sequential([\n",
        "  tensorflow.keras.layers.Dense(100, input_shape = (126, ), activation ='relu'),\n",
        "  tensorflow.keras.layers.Dense(100, activation ='relu'),  \n",
        "  tensorflow.keras.layers.Dense(100, activation ='relu'),  \n",
        "  tensorflow.keras.layers.Dense(100, activation ='relu'),  \n",
        "  tensorflow.keras.layers.Dense(8, activation ='softmax')\n",
        "])\n",
        "\n",
        "#Optimizer 설정\n",
        "Adam = tensorflow.keras.optimizers.Adam # 최적화 기재를 더 잘 만지고 싶다면, 이런 식으로 객체에 받아온 후에 세부조정 해줘야 함.\n",
        "model.compile(optimizer= Adam(lr = 0.000025), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzaF865bnHx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#신경망에 투입 가능한 형식(Tensorflow.data.dataset)으로 데이터 가공\n",
        "dataset = tensorflow.data.Dataset.from_tensor_slices((data_train.values,Response.values))\n",
        "\n",
        "#Validation Set 구성(60000여 행 데이터 중 6000개)\n",
        "validation_dataset = dataset.take(6000) \n",
        "train_dataset = dataset.skip(6000)\n",
        "\n",
        "#Shuffle 및 Batch 구성\n",
        "train_dataset = train_dataset.shuffle(len(impu_train)-6000).batch(16)\n",
        "validation_dataset = validation_dataset.shuffle(6000).batch(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6P3JPIRmEmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습 진행 및 log 파일 생성\n",
        "from keras.callbacks import CSVLogger\n",
        "csv_logger = CSVLogger('log_100_300.csv', append=True, separator=',')\n",
        "history = model.fit(train_dataset, epochs=100,callbacks = [csv_logger], validation_data= validation_dataset) \n",
        "\n",
        "#학습 결과물 저장\n",
        "model.save('Pru_Keras_3layer100.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6463Wyc7F9Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습 결과물 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuBx2oL3Aqmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test set에 대해 전처리\n",
        "test_set = pd.read_csv(data_in_path + 'test_regression_ascending.csv')\n",
        "Id_list = test_set.pop('Id')\n",
        "test_set = test_set.loc[:,'Product_Info_1':'Medical_Keyword_48']\n",
        "def string2int(string):\n",
        "  return ord(string[:1])+int(string[1:2])\n",
        "test_set[\"Product_Info_2\"] = test_set[\"Product_Info_2\"].apply(lambda s: string2int(s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYnQNI9rBdMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle에 제출하기 위한 csv파일 작성\n",
        "import csv\n",
        "with open('test_prediction_300.csv', 'w',encoding = 'cp949') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['Id','Response'])\n",
        "  out = model.predict(test_set, batch_size = 16)\n",
        "  for i in range(len(out)):\n",
        "    writer.writerow([Id_list[i],int(np.where(max(out[i])==out[i])[0])+1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}