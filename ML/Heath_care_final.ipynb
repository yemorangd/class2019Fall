{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heath_care_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCb0Wa8AZWCM",
        "colab_type": "text"
      },
      "source": [
        "공공데이터포털에 공개된 국민건강보험가입자 진료내역 정보(https://www.data.go.kr/dataset/15007115/fileData.do) 중 2016년 진료내역에 대한 분석을 실시.\n",
        "\n",
        "본래 1200만여개의 진료기록에 대한 19칼럼의 데이터로 구성되었으나, 100만명의 국민건강보험 가입자들에 대한 90칼럼의 데이터로 재구성해 분석함.\n",
        "\n",
        "재구성한 데이터는 다음과 같음. \n",
        "1. 개인별 정보 : ID/성별/연령대/1년간 총 요양일 수/1년간 총 처방일수/1년간 총 방문횟수 \n",
        "2. 각 진료별 상병(질병유형)코드 : 주상병 (21칼럼 할당), 부상병(23칼럼 할당)\n",
        "3. 서식코드 : 의과 입원, 의과 외래, 보건기관 외래에 대해 총 3칼럼 할당\n",
        "4. 진료과목 코드 : 일반의, 내과, 신경과, 정신과, 외과 등 총 34칼럼 할당\n",
        "5. 심결가산율 : 0.15(의원, 보건의료원 등), 0.2(일반 병원), 0.3(상급 종합병원)의 3칼럼 할당\n",
        "\n",
        "기본 데이터에 포함되어있는 '심결본인부담금'을 실제 부담 의료비 금액으로 설정한 후, 개인별 부담금의 8분위 분위수를 계산하였음.\n",
        "\n",
        "이후 Keras 및 Tensorflow를 이용하여 개인별 데이터를 input으로 받고, 1부터 8까지의 의료비 지출 분위수를 예측 output으로 산출하는 신경망 모델을 구성하였음.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkydHDy-R8S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load modules and check file configuration\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "import os\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "drive.mount(\"/content/drive/\", force_remount = True)\n",
        "path = '/content/drive/My Drive/ML/건강보험'\n",
        "os.chdir(path)\n",
        "data_in_path = './input/'\n",
        "data_out_path = './out/'\n",
        "\n",
        "#Load data\n",
        "data = pd.read_csv(data_in_path + 'gun_train.csv', encoding = 'cp949')\n",
        "test_data = pd.read_csv(data_in_path + 'gun_test.csv', encoding='cp949')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5UF2BSA6G98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training data generation\n",
        "data_train = data.loc[:,'성별코드':'quartile']\n",
        "Response = data_train.pop('quartile')\n",
        "Response = Response-1\n",
        "\n",
        "#Into Tf.dataset \n",
        "dataset = tensorflow.data.Dataset.from_tensor_slices((data_train.values,Response.values))\n",
        "\n",
        "#Validation Split\n",
        "validation_dataset = dataset.take(100000) \n",
        "train_dataset = dataset.skip(100000)\n",
        "train_dataset = train_dataset.shuffle(700000).batch(16)\n",
        "validation_dataset = validation_dataset.shuffle(100000).batch(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYV7ALfvW7xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test data generation\n",
        "data_test = test_data.loc[:,'성별코드':'quartile']\n",
        "test_Response = data_test.pop('quartile')\n",
        "test_Response = test_Response-1\n",
        "\n",
        "#Into Tf.dataset\n",
        "dataset_test = tensorflow.data.Dataset.from_tensor_slices((data_test.values,test_Response.values))\n",
        "test_dataset = dataset_test.shuffle(200000).batch(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0zNIsPhFQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model generation\n",
        "model = tensorflow.keras.models.Sequential([\n",
        "  tensorflow.keras.layers.Dense(100, input_shape = (89, ), activation ='relu'),\n",
        "  tensorflow.keras.layers.Dense(100,activation = 'relu'),\n",
        "  tensorflow.keras.layers.Dense(100,activation = 'relu'),\n",
        "  tensorflow.keras.layers.Dense(100,activation = 'relu'),\n",
        "  tensorflow.keras.layers.Dense(100, activation ='relu'),\n",
        "  tensorflow.keras.layers.Dense(100,activation = 'relu'),\n",
        "  tensorflow.keras.layers.Dense(8, activation ='softmax') #최종 노드 값은 합이 1이 되도록 분할한 값 10개.\n",
        "])\n",
        "\n",
        "#Set optimizer and compile model\n",
        "Adam = tensorflow.keras.optimizers.Adam # 최적화 기재를 더 잘 만지고 싶다면, 이런 식으로 객체에 받아온 후에 세부조정 해줘야 함.\n",
        "model.compile(optimizer= Adam(lr = 0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Check Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwIG7Ohl45V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If needed, load previous weights\n",
        "weight_in_path ='./weights/'\n",
        "model.load_weights(weight_in_path + 'Health_Full_600.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6P3JPIRmEmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train model\n",
        "from keras.callbacks import CSVLogger\n",
        "a = 'Health_Full_600'\n",
        "csv_logger = CSVLogger('./log'+a+'.csv', append=True, separator=',')\n",
        "history = model.fit(train_dataset, epochs=30, callbacks=[csv_logger],validation_data= validation_dataset) \n",
        "\n",
        "#Save weights\n",
        "weight_in_path ='./weights/'\n",
        "model.save(weight_in_path + a +'.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWFj5WbJFNJC",
        "colab_type": "code",
        "outputId": "bf59de61-fc3f-4e1a-9b68-654da52a8103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#Evaluation\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500/12500 [==============================] - 17s 1ms/step - loss: 0.9697 - acc: 0.6031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9697329196381569, 0.603115]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6463Wyc7F9Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}