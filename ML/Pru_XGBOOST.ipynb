{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Pru_XGBOOST.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"1btXuCORU7yy","colab_type":"code","colab":{}},"source":["import pandas as pd \n","import numpy as np \n","import xgboost as xgb\n","from scipy.optimize import fmin_powell\n","from ml_metrics import quadratic_weighted_kappa #이거 평가치용 코드니까 신경 안 써도 됨.\n","\n","def eval_wrapper(yhat, y):  \n","    y = np.array(y)\n","    y = y.astype(int)\n","    yhat = np.array(yhat)\n","    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n","    return quadratic_weighted_kappa(yhat, y)\n","    \n","def get_params():\n","    params = {}\n","    params[\"objective\"] = \"reg:linear\"\n","    params[\"max_depth\"] = 7\n","    params[\"eta\"] = 0.05\n","    params[\"min_child_weight\"] = 360\n","    params[\"subsample\"] = 0.85\n","    params[\"colsample_bytree\"] = 0.3\n","    params[\"silent\"] = 1\n","    plst = list(params.items())\n","\n","    return plst\n","    \n","def score_offset(data, bin_offset, sv, scorer=eval_wrapper):\n","    # data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n","    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n","    score = scorer(data[1], data[2])\n","    return score\n","    \n","def apply_offsets(data, offsets):\n","    for j in range(num_classes):\n","        data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j]\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vq4Iub7_U7y3","colab_type":"code","colab":{},"outputId":"3935113c-f3b6-419b-b496-6d55a141db99"},"source":["# global variables\n","columns_to_drop = ['Id', 'Response'] #, 'Medical_History_10','Medical_History_24']\n","xgb_num_rounds = 720\n","num_classes = 8\n","missing_indicator = -1000\n","\n","\n","print(\"Load the data using pandas\")\n","train = pd.read_csv(\"./input/train.csv\")\n","test = pd.read_csv(\"./input/test.csv\")\n","\n","# combine train and test\n","all_data = train.append(test)\n","\n","# Found at https://www.kaggle.com/marcellonegro/prudential-life-insurance-assessment/xgb-offset0501/run/137585/code\n","# create any new variables    \n","all_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]\n","all_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]\n","\n","# factorize categorical variables\n","# 설명은 이런 것 참고, 단순히 수치변인이 아닌 내용을 수치화해주는듯, 최소한 범주변인으로는 변환해주는 것.\n","all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\n","all_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\n","all_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n","\n","all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n","\n","med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n","all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n","\n","print('Eliminate missing values')    \n","all_data.fillna(missing_indicator, inplace=True)\n","\n","# fix the dtype on the label column\n","all_data['Response'] = all_data['Response'].astype(int)\n","\n","# split train and test\n","train = all_data[all_data['Response']>0].copy()\n","test = all_data[all_data['Response']<1].copy() #test는 response 칼럼이 아예 비어 있어서, -1000이 다 들어가 있기 때문에 이렇게 봄.\n","\n","# convert data to xgb data structure\n","xgtrain = xgb.DMatrix(train.drop(columns_to_drop, axis=1), train['Response'].values, \n","                        missing=missing_indicator)\n","xgtest = xgb.DMatrix(test.drop(columns_to_drop, axis=1), label=test['Response'].values, \n","                        missing=missing_indicator)    \n","\n","# get the parameters for xgboost\n","plst = get_params()\n","print(plst)      \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Load the data using pandas\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Users\\goldh\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n","of pandas will change to not sort by default.\n","\n","To accept the future behavior, pass 'sort=False'.\n","\n","To retain the current behavior and silence the warning, pass 'sort=True'.\n","\n","  sort=sort)\n"],"name":"stderr"},{"output_type":"stream","text":["Eliminate missing values\n","[('objective', 'reg:linear'), ('eta', 0.05), ('min_child_weight', 360), ('subsample', 0.85), ('colsample_bytree', 0.3), ('silent', 1), ('max_depth', 7)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WbaYbvHSU7y9","colab_type":"code","colab":{},"outputId":"ff3982d5-2c88-4503-8555-2344f1ebcbc1"},"source":["# train model\n","model = xgb.train(plst, xgtrain, xgb_num_rounds) \n","\n","# get preds\n","train_preds = model.predict(xgtrain, ntree_limit=model.best_iteration)\n","print('Train score is:', eval_wrapper(train_preds, train['Response'])) \n","test_preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n","\n","# train offsets \n","offsets = np.array([0.1, -1, -2, -1, -0.8, 0.02, 0.8, 1])\n","offset_preds = np.vstack((train_preds, train_preds, train['Response'].values))\n","offset_preds = apply_offsets(offset_preds, offsets)\n","opt_order = [6,4,5,3]\n","for j in opt_order:\n","    train_offset = lambda x: -score_offset(offset_preds, x, j) * 100\n","    offsets[j] = fmin_powell(train_offset, offsets[j], disp=False)\n","\n","print('Offset Train score is:', eval_wrapper(offset_preds[1], train['Response'])) \n","\n","# apply offsets to test\n","data = np.vstack((test_preds, test_preds, test['Response'].values))\n","data = apply_offsets(data, offsets)\n","\n","final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)\n","\n","preds_out = pd.DataFrame({\"Id\": test['Id'].values, \"Response\": final_test_preds})\n","preds_out = preds_out.set_index('Id')\n","preds_out.to_csv('xgb_offset_submission.csv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train score is: 0.6515752806586164\n","Offset Train score is: 0.7039291534748933\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hzlKeICrU7zC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}